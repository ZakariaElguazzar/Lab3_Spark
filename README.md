Je vais d'abord analyser votre rapport et vous proposer des am√©liorations, puis cr√©er le README.md.

## Analyse du rapport LaTeX et suggestions d'am√©lioration :

### **Probl√®mes identifi√©s :**

1. **Manque de d√©tails techniques sp√©cifiques** :
   - Les codes sources ne sont pas complets, juste des extraits
   - Pas d'explication d√©taill√©e des transformations RDD
   - Pas de sch√©ma d'architecture visuel

2. **R√©sultats incomplets** :
   - Pas de captures d'√©cran des interfaces web (Spark UI, HDFS UI)
   - Pas de m√©triques de performance comparatives
   - Pas d'exemples concrets de sorties HDFS

3. **Structure √† am√©liorer** :
   - Pas de section sur les bonnes pratiques
   - Pas d'analyse des performances
   - Pas de d√©tails sur le fichier `pom.xml`

4. **Aspect visuel** :
   - Pas de diagrammes ou sch√©mas
   - Les tableaux pourraient √™tre mieux pr√©sent√©s

### **Questions pour am√©liorer le rapport :**

1. **Architecture Docker** :
   - Avez-vous des captures d'√©cran des interfaces web (Spark Master UI, HDFS Namenode UI) ?
   - Pouvez-vous partager le contenu exact de votre `pom.xml` ?

2. **Ex√©cution sur cluster** :
   - Quels sont les logs exacts lors du `spark-submit` ?
   - Avez-vous des m√©triques de temps d'ex√©cution (local vs cluster) ?
   - Pouvez-vous montrer le contenu des r√©pertoires HDFS g√©n√©r√©s ?

3. **D√©tails techniques** :
   - Quelle version de Spark, Hadoop et Java avez-vous utilis√©e ?
   - Comment avez-vous g√©r√© les d√©pendances dans Maven ?
   - Avez-vous rencontr√© des probl√®mes de m√©moire ou de performance ?

4. **Validation des r√©sultats** :
   - Avez-vous v√©rifi√© la coh√©rence des r√©sultats entre local et HDFS ?
   - Comment avez-vous valid√© que les donn√©es √©taient bien distribu√©es sur HDFS ?

### **Actions propos√©es pour am√©liorer le rapport :**

**ACTION 1 :** Ajoutez des sections sur :
- La configuration exacte du cluster (RAM, CPU allou√©s)
- Les bonnes pratiques de d√©veloppement Spark
- L'analyse des performances avec diff√©rentes tailles de donn√©es

**ACTION 2 :** Incluez des √©l√©ments visuels :
- Diagramme d'architecture Docker
- Capture d'√©cran de Spark UI montrant les jobs
- Capture d'√©cran de HDFS UI montrant les fichiers

**ACTION 3 :** Ajoutez des d√©tails techniques :
- Contenu complet du `pom.xml`
- Commandes exactes utilis√©es avec leurs sorties
- Exemples de fichiers de r√©sultats g√©n√©r√©s

**ACTION 4 :** D√©crivez les probl√®mes rencontr√©s en d√©tail :
- Messages d'erreur exacts
- Solutions techniques d√©taill√©es
- Optimisations apport√©es

---

Maintenant, voici une premi√®re version du **README.md** bas√©e sur votre rapport :

```markdown
# TP1 - Programmation des RDDs avec Spark

## üìã Description du Projet
Ce projet contient les impl√©mentations pour le TP1 de programmation des RDDs avec Apache Spark. Il comprend deux exercices principaux :
1. Analyse des ventes par ville et par ann√©e
2. Analyse de fichiers de logs Apache

## üèóÔ∏è Architecture Technique

### Environnement Docker
Le projet utilise une architecture Docker compos√©e de :
- **HDFS Cluster** : Namenode + Datanode
- **YARN Cluster** : ResourceManager + NodeManager  
- **Spark Cluster** : Spark Master + Spark Worker

### Services et Ports
| Service | Ports | URL Interface Web |
|---------|-------|-------------------|
| Namenode | 9870, 8020 | http://localhost:9870 |
| ResourceManager | 8088 | http://localhost:8088 |
| Spark Master | 7077, 8080 | http://localhost:8080 |

## üìÅ Structure du Projet
```
spark-test/
‚îú‚îÄ‚îÄ src/main/java/org/example/
‚îÇ   ‚îú‚îÄ‚îÄ VenteParVilleLocal.java      # Ventes par ville (mode local)
‚îÇ   ‚îú‚îÄ‚îÄ VenteParVilleAnneeLocal.java # Ventes par ville/ann√©e (mode local)
‚îÇ   ‚îú‚îÄ‚îÄ VenteParVilleHDFS.java       # Ventes par ville (mode cluster HDFS)
‚îÇ   ‚îú‚îÄ‚îÄ VenteParVilleAnneeHDFS.java  # Ventes par ville/ann√©e (mode cluster HDFS)
‚îÇ   ‚îî‚îÄ‚îÄ LogAnalyzer.java             # Analyse de logs Apache
‚îú‚îÄ‚îÄ pom.xml                          # Configuration Maven
‚îî‚îÄ‚îÄ target/spark-test-1.0-SNAPSHOT.jar
```

## üöÄ Installation et Configuration

### Pr√©requis
- Docker et Docker Compose
- Java 8 ou sup√©rieur
- Maven 3.6+
- Git

### 1. Cloner le projet
```bash
git clone <repository-url>
cd spark-test
```

### 2. D√©marrer l'infrastructure Docker
```bash
docker-compose up -d
```

### 3. V√©rifier les services
```bash
# V√©rifier que tous les services sont en cours d'ex√©cution
docker-compose ps

# Acc√©der √† l'interface web HDFS
# Ouvrir : http://localhost:9870

# Acc√©der √† l'interface web Spark
# Ouvrir : http://localhost:8080
```

## üìä Donn√©es d'Entr√©e

### Fichier ventes.txt
Format : `date ville produit prix`
```
2024-01-15 Paris Ordinateur 1200.50
2024-01-16 Lyon Smartphone 800.00
2024-01-17 Paris Tablette 450.75
2024-02-10 Marseille Ordinateur 1100.00
2023-12-20 Lyon Ordinateur 1150.00
2023-12-22 Paris Souris 25.99
```

### Fichier access.log
Format Apache Common Log Format :
```
127.0.0.1 - - [10/Oct/2025:09:15:32 +0000] "GET /index.html HTTP/1.1" 200 1024
192.168.1.10 - john [10/Oct/2025:09:17:12 +0000] "POST /login HTTP/1.1" 302 512
```

## üíª Compilation et Ex√©cution

### Compilation avec Maven
```bash
mvn clean compile
mvn package  # G√©n√®re le fichier JAR
```

### Mode Local (D√©veloppement)

#### Ventes par Ville
```bash
mvn exec:java -Dexec.mainClass="org.example.VenteParVilleLocal"
```

#### Ventes par Ville et Ann√©e
```bash
mvn exec:java -Dexec.mainClass="org.example.VenteParVilleAnneeLocal"
```

#### Analyse de Logs
```bash
mvn exec:java -Dexec.mainClass="org.example.LogAnalyzer"
```

### Mode Cluster (Production)

#### Pr√©paration des donn√©es sur HDFS
```bash
# Copier les donn√©es vers le container namenode
docker cp /chemin/vers/ventes.txt namenode:/data/ventes.txt

# Transf√©rer vers HDFS
docker exec namenode hdfs dfs -put /data/ventes.txt /ventes.txt

# V√©rifier le fichier
docker exec namenode hdfs dfs -ls /
```

#### D√©ploiement du JAR
```bash
# Copier le JAR vers le spark-master
docker cp target/spark-test-1.0-SNAPSHOT.jar spark-master:/opt/spark/work-dir/
```

#### Ex√©cution sur le Cluster

**Ventes par Ville (HDFS) :**
```bash
docker exec spark-master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --class org.example.VenteParVilleHDFS \
  /opt/spark/work-dir/spark-test-1.0-SNAPSHOT.jar
```

**Ventes par Ville et Ann√©e (HDFS) :**
```bash
docker exec spark-master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --class org.example.VenteParVilleAnneeHDFS \
  /opt/spark/work-dir/spark-test-1.0-SNAPSHOT.jar
```

## üìà R√©sultats Attendus

### Application Ventes
```
=== Total des ventes par ville ===
Lyon: 1950.00
Marseille: 1100.00
Paris: 1677.24

=== Total des ventes par ville et par ann√©e ===
Lyon-2023: 1150.00
Lyon-2024: 950.25
Marseille-2024: 1100.00
Paris-2023: 25.99
Paris-2024: 2401.75
```

### Application Logs
```
=== ANALYSE DE LOGS APACHE ===
1. STATISTIQUES GLOBALES
   Total des requ√™tes: 21

2. TOP 5 IPs
   127.0.0.1: 4 requ√™tes
   192.168.1.10: 3 requ√™tes
   192.168.1.11: 3 requ√™tes

3. TOP 5 RESSOURCES
   /index.html: 2 requ√™tes
   /api/data?id=123: 1 requ√™te
   /api/status: 1 requ√™te

4. CODES HTTP
   Code 200: 12 (57.1%)
   Code 404: 2 (9.5%)
   Code 500: 1 (4.8%)
```

## üîß Probl√®mes Rencontr√©s et Solutions

### Probl√®me 1 : Format de Date Inattendu
**Sympt√¥me** : L'ann√©e apparaissait toujours comme "Inconnue"  
**Cause** : Format `AAAA-MM-JJ` au lieu de `JJ/MM/AAAA` attendu  
**Solution** : Modification du parsing dans `VenteParVilleAnneeLocal.java`

### Probl√®me 2 : Connexion HDFS
**Sympt√¥me** : √âchec de connexion √† `namenode:8020`  
**Cause** : Configuration r√©seau Docker  
**Solution** : V√©rification des ports et du r√©seau Docker

### Probl√®me 3 : Permissions HDFS
**Sympt√¥me** : Impossible d'√©crire dans HDFS  
**Solution** : 
```bash
docker exec namenode hdfs dfs -chmod 777 /
```

## üìä Comparaison Mode Local vs Cluster

| Aspect | Mode Local | Mode Cluster (HDFS) |
|--------|------------|---------------------|
| Configuration | Simple | Complexe |
| D√©pendances | Aucune | HDFS/YARN requis |
| Performance | Limit√©e | Scalable horizontalement |
| Utilisation | D√©veloppement | Production |

## üéØ Acquis du TP

- ‚úÖ Programmation RDD avec Spark en Java
- ‚úÖ Utilisation des modes local et cluster
- ‚úÖ Manipulation de HDFS et YARN
- ‚úÖ Analyse de donn√©es avec transformations RDD
- ‚úÖ Packaging et d√©ploiement d'applications Spark
- ‚úÖ D√©bogage d'applications distribu√©es

## üîÆ Perspectives d'Am√©lioration

1. **Optimisation** : Utiliser DataFrames/Spark SQL
2. **Monitoring** : Int√©grer Spark History Server
3. **Tests** : Ajouter des tests unitaires
4. **CI/CD** : Pipeline d'int√©gration continue
5. **Orchestration** : Utiliser Kubernetes au lieu de Docker Compose

## üìö R√©f√©rences

- [Documentation Apache Spark](https://spark.apache.org/docs/latest/)
- [Documentation Apache Hadoop](https://hadoop.apache.org/docs/)
- [Docker Hub - Apache Hadoop](https://hub.docker.com/r/apache/hadoop)
- [Format des logs Apache](https://httpd.apache.org/docs/2.4/logs.html)

## üë§ Auteur
**Zakaria EL GUAZZAR**  
√âtudiant en Big Data et Analytics

## üìÑ Licence
Ce projet est destin√© √† des fins √©ducatives dans le cadre acad√©mique.
```

Ce README.md est complet et contient :
- Toutes les informations techniques n√©cessaires
- Les √©tapes d'installation et d'ex√©cution
- Les r√©sultats attendus
- Les probl√®mes et solutions
- Les r√©f√©rences

**Question pour vous :** Souhaitez-vous que j'ajoute des sections sp√©cifiques comme :
1. Des captures d'√©cran des interfaces web ?
2. Le contenu exact du `pom.xml` ?
3. Des exemples de logs d'ex√©cution ?
4. Un diagramme d'architecture ?

Cela rendrait le README encore plus complet et utile pour d'autres utilisateurs.
